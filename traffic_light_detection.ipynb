{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "def detect_and_annotate_frame(frame):\n",
        "    \"\"\"\n",
        "    Detects and classifies traffic lights in a single frame.\n",
        "\n",
        "    Args:\n",
        "        frame: The input video frame (as a NumPy array).\n",
        "\n",
        "    Returns:\n",
        "        The frame with detected traffic lights annotated with bounding boxes and labels.\n",
        "    \"\"\"\n",
        "    # Convert frame from BGR to HSV color space for better color segmentation\n",
        "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Define HSV color ranges for red, yellow, and green\n",
        "\n",
        "    lower_red1 = np.array([0, 120, 90])\n",
        "    upper_red1 = np.array([10, 255, 255])\n",
        "    lower_red2 = np.array([170, 120, 90])\n",
        "    upper_red2 = np.array([180, 255, 255])\n",
        "\n",
        "    lower_yellow = np.array([20, 100, 100])\n",
        "    upper_yellow = np.array([35, 255, 255])\n",
        "\n",
        "    lower_green = np.array([40, 70, 70])\n",
        "    upper_green = np.array([90, 255, 255])\n",
        "\n",
        "    # Create binary masks for each color\n",
        "    red_mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
        "    red_mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
        "    red_mask = cv2.add(red_mask1, red_mask2)\n",
        "    yellow_mask = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
        "    green_mask = cv2.inRange(hsv, lower_green, upper_green)\n",
        "\n",
        "    # Store masks and their corresponding labels/colors\n",
        "    masks = {\"Red\": red_mask, \"Yellow\": yellow_mask, \"Green\": green_mask}\n",
        "\n",
        "    # Process each mask to find and draw contours\n",
        "    for color_name, mask in masks.items():\n",
        "        # Find contours (outlines of the colored regions)\n",
        "        contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        for contour in contours:\n",
        "            # --- Object Validation using size/shape constraints ---\n",
        "            area = cv2.contourArea(contour)\n",
        "            if area > 200: # Filter out very small, noisy detections\n",
        "                x, y, w, h = cv2.boundingRect(contour)\n",
        "                aspect_ratio = w / float(h)\n",
        "\n",
        "                # Check for a somewhat circular/square shape\n",
        "                if 0.5 < aspect_ratio < 1.8:\n",
        "                    # Draw bounding box on the original frame\n",
        "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "                    # Add a text label\n",
        "                    cv2.putText(frame, color_name, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "    return frame\n",
        "\n",
        "# --- Main Video Processing Pipeline ---\n",
        "\n",
        "\n",
        "input_video_path = 'traffic_test.mp4'\n",
        "output_video_path = 'output_demo.mp4'\n",
        "\n",
        "# Check if the input video file exists\n",
        "if not os.path.exists(input_video_path):\n",
        "    print(f\"Error: Input file not found at '{input_video_path}'.\")\n",
        "    print(\"Please make sure you have uploaded the video and the filename is correct.\")\n",
        "else:\n",
        "    # Open the video file for reading\n",
        "    cap = cv2.VideoCapture(input_video_path)\n",
        "\n",
        "    # Get video properties (width, height, frames per second)\n",
        "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "    # Define the video codec and create a VideoWriter object to save the output\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "    print(f\"Processing video: '{input_video_path}'...\")\n",
        "    print(\"This may take a few moments depending on the video length.\")\n",
        "\n",
        "    # Loop through every frame of the video\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            # End of video\n",
        "            break\n",
        "\n",
        "        # Process the frame to detect and annotate traffic lights\n",
        "        processed_frame = detect_and_annotate_frame(frame)\n",
        "\n",
        "        # Write the processed frame to the output video file\n",
        "        out.write(processed_frame)\n",
        "\n",
        "    # Release the video capture and writer objects\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    print(\"-\" * 30)\n",
        "    print(\"Video processing complete!\")\n",
        "    print(f\"Annotated video saved as: '{output_video_path}'\")\n",
        "    print(\"-\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqBSXQbURxzX",
        "outputId": "ef0f75a2-f955-42e9-f151-9bc93c3374e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing video: 'traffic_test.mp4'...\n",
            "This may take a few moments depending on the video length.\n",
            "------------------------------\n",
            "Video processing complete!\n",
            "Annotated video saved as: 'output_demo.mp4'\n",
            "------------------------------\n"
          ]
        }
      ]
    }
  ]
}